{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13139007,"sourceType":"datasetVersion","datasetId":8324136},{"sourceId":13140213,"sourceType":"datasetVersion","datasetId":8324975}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-22T17:03:26.453885Z","iopub.execute_input":"2025-09-22T17:03:26.454167Z","iopub.status.idle":"2025-09-22T17:03:26.464158Z","shell.execute_reply.started":"2025-09-22T17:03:26.454145Z","shell.execute_reply":"2025-09-22T17:03:26.463514Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/data-reviews/texts.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\nimport random\nfrom typing import List, Tuple\n\ndef create_synthetic_space_data(\n    texts: List[str],\n    max_samples: int = 10000\n) -> List[Tuple[str, List[int]]]:\n    \"\"\"\n    Генерирует синтетические примеры для задачи восстановления пробелов.\n\n    Args:\n        texts: список исходных предложений на русском языке,\n               а также с возможными английскими словами, числами, запятыми и апострофами.\n        max_samples: максимальное количество генерируемых примеров.\n\n    Returns:\n        Список кортежей (text_no_spaces, space_positions):\n            text_no_spaces — строка без пробелов;\n            space_positions — список индексов, перед которыми должен быть пробел.\n    \"\"\"\n    synthetic_data = []\n    # Регулярное выражение: сохраняем кириллицу, латиницу, цифры, пробелы, запятые и апострофы\n    pattern = re.compile(r\"[^а-яёА-ЯЁa-zA-Z0-9\\s,\\'’]\")\n    for text in texts:\n        # Очищаем текст, оставляя нужные символы, переводим в нижний регистр\n        clean = pattern.sub(\"\", text).strip()[:-8]\n        words = clean.split()\n        # Фильтрация по длине предложения\n        if len(words) < 3 or len(words) > 20:\n            continue\n\n        # Склеиваем слова без пробелов\n        text_no_spaces = \"\".join(words)\n\n        # Вычисляем позиции пробелов\n        positions = []\n        pos = 0\n        for i, w in enumerate(words):\n            if i > 0:\n                positions.append(pos)\n            pos += len(w)\n\n        synthetic_data.append((text_no_spaces, positions))\n        if len(synthetic_data) >= max_samples:\n            break\n\n    return synthetic_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T17:10:58.086891Z","iopub.execute_input":"2025-09-22T17:10:58.087607Z","iopub.status.idle":"2025-09-22T17:10:58.093844Z","shell.execute_reply.started":"2025-09-22T17:10:58.087583Z","shell.execute_reply":"2025-09-22T17:10:58.093254Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"with open('/kaggle/input/data-reviews/texts.csv', 'r') as f:\n    f = f.readlines()\nprint(len(f))\ndata = create_synthetic_space_data(f[1:], max_samples=9999999)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T17:12:01.359100Z","iopub.execute_input":"2025-09-22T17:12:01.359368Z","iopub.status.idle":"2025-09-22T17:12:02.147363Z","shell.execute_reply.started":"2025-09-22T17:12:01.359349Z","shell.execute_reply":"2025-09-22T17:12:02.146776Z"}},"outputs":[{"name":"stdout","text":"101893\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"data[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T17:12:04.126794Z","iopub.execute_input":"2025-09-22T17:12:04.127078Z","iopub.status.idle":"2025-09-22T17:12:04.132123Z","shell.execute_reply.started":"2025-09-22T17:12:04.127055Z","shell.execute_reply":"2025-09-22T17:12:04.131346Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('товарнепришел,продавецпродлилзащитубезмоегосогласияотпродавцаодниобещания',\n [5, 7, 14, 22, 29, 35, 38, 43, 51, 53, 61, 65])"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"len(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T17:12:04.375916Z","iopub.execute_input":"2025-09-22T17:12:04.376626Z","iopub.status.idle":"2025-09-22T17:12:04.381143Z","shell.execute_reply.started":"2025-09-22T17:12:04.376603Z","shell.execute_reply":"2025-09-22T17:12:04.380417Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"63666"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom typing import List, Tuple\n\nclass SpaceRestorationDataset(Dataset):\n    \"\"\"\n    Класс-датасет для задачи восстановления пробелов:\n    - examples: список кортежей (текст_без_пробелов, позиции_пробелов)\n    - для каждого примера создаём метки на уровне сабтокенов с учётом символных позиций\n    \"\"\"\n    def __init__(\n        self,\n        examples: List[Tuple[str, List[int]]],\n        tokenizer_name: str = \"ai-forever/ruRoberta-large\",\n        max_length: int = 128\n    ):\n        # Сохраняем примеры\n        self.examples = examples\n        # Инициализируем fast-токенизатор Roberta с add_prefix_space=True,\n        # чтобы корректно работать с предтокенизированными строками\n        self.tokenizer = AutoTokenizer.from_pretrained(\n            tokenizer_name, use_fast=True, add_prefix_space=True\n        )\n        # Максимальная длина последовательности для паддинга/транкации\n        self.max_length = max_length\n\n    def __len__(self):\n        # Количество примеров\n        return len(self.examples)\n    \n    def __getitem__(self, idx: int):\n        # Получаем текст без пробелов и список позиций пробелов\n        text_ns, space_positions = self.examples[idx]\n\n        # 1. Создаём array нулей длиной текста, затем отмечаем char-level метки\n        char_labels = [0] * len(text_ns)\n        for p in space_positions:\n            if 0 <= p < len(char_labels):\n                char_labels[p] = 1\n\n        # 2. Токенизируем строку целиком, запрашивая offsets для выравнивания меток\n        enc = self.tokenizer(\n            text_ns,\n            return_offsets_mapping=True,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=self.max_length\n        )\n        input_ids = enc[\"input_ids\"]             # индексы сабтокенов\n        attention_mask = enc[\"attention_mask\"]   # маска паддинга\n        offsets = enc[\"offset_mapping\"]          # соответствие токен→спану символов\n\n        # 3. Выравниваем метки на уровне токенов:\n        #    если в диапазоне одного токена есть хотя бы один char_label=1 → метка=1\n        token_labels = []\n        for (start, end) in offsets:\n            if start == end:\n                # [CLS], [SEP], паддинг\n                token_labels.append(0)\n            else:\n                # проверяем все символы в диапазоне\n                label = 0\n                for i in range(start, end):\n                    if char_labels[i] == 1:\n                        label = 1\n                        break\n                token_labels.append(label)\n\n        # 4. Конвертируем всё в тензоры и возвращаем в виде словаря\n        return {\n            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"labels\": torch.tensor(token_labels, dtype=torch.long),\n        }\n\n\nfrom sklearn.model_selection import train_test_split\n\n# data — это список примеров [(текст_без_пробелов, позиции_пробелов), ...]\ntrain_ex, val_ex = train_test_split(data, test_size=0.2, random_state=42)\n\n# Инициализируем датасеты с тем же токенизатором для train и val\ntrain_dataset = SpaceRestorationDataset(\n    train_ex,\n    tokenizer_name=\"ai-forever/ruRoberta-large\",\n    max_length=128\n)\nval_dataset = SpaceRestorationDataset(\n    val_ex,\n    tokenizer_name=\"ai-forever/ruRoberta-large\",\n    max_length=128\n)\n\n# Создаём DataLoader:\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\n# Проверка форматов первого батча\nbatch = next(iter(train_loader))\nprint(\"input_ids:\", batch[\"input_ids\"].shape)        # (16, 128)\nprint(\"attention_mask:\", batch[\"attention_mask\"].shape)  # (16, 128)\nprint(\"labels:\", batch[\"labels\"].shape)              # (16, 128)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:00.644568Z","iopub.execute_input":"2025-09-22T18:54:00.644843Z","iopub.status.idle":"2025-09-22T18:54:02.200751Z","shell.execute_reply.started":"2025-09-22T18:54:00.644823Z","shell.execute_reply":"2025-09-22T18:54:02.199962Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 128])\ntorch.Size([16, 128])\ntorch.Size([16, 128])\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"!pip install pytorch-crf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T17:26:36.382224Z","iopub.execute_input":"2025-09-22T17:26:36.382495Z","iopub.status.idle":"2025-09-22T17:26:39.697485Z","shell.execute_reply.started":"2025-09-22T17:26:36.382479Z","shell.execute_reply":"2025-09-22T17:26:39.696506Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting pytorch-crf\n  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\nDownloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\nInstalling collected packages: pytorch-crf\nSuccessfully installed pytorch-crf-0.7.2\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:39.565196Z","iopub.execute_input":"2025-09-22T18:54:39.565770Z","iopub.status.idle":"2025-09-22T18:54:39.868513Z","shell.execute_reply.started":"2025-09-22T18:54:39.565747Z","shell.execute_reply":"2025-09-22T18:54:39.867927Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom transformers import AutoModel\nfrom torchcrf import CRF\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom tqdm.auto import tqdm\n\nclass RuBERTCRFSpaceRestoration(nn.Module):\n    \"\"\"\n    Модель RuRoBERTa + CRF для восстановления пропущенных пробелов.\n    Архитектура:\n      - Pretrained Transformer (ruRoberta-large) для получения контекстных эмбеддингов.\n      - Dropout для регуляризации.\n      - Linear-классификатор на hidden_size → 2 (0/1 метки).\n      - CRF-слой для моделирования зависимостей между позициями пробелов.\n    \"\"\"\n    def __init__(\n        self,\n        model_name: str = \"ai-forever/ruRoberta-large\",\n        num_labels: int = 2\n    ):\n        super().__init__()\n        # 1. Pretrained Transformer\n        self.bert = AutoModel.from_pretrained(model_name)\n        # 2. Dropout перед классификатором\n        self.dropout = nn.Dropout(0.1)\n        # 3. Классификатор для предсказания эмиссий\n        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n        # 4. CRF-слой для последовательной разметки\n        self.crf = CRF(num_labels, batch_first=True)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        # Вычисляем эмбеддинги\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = self.dropout(outputs.last_hidden_state)\n        # Получаем эмиссии (логиты) для CRF\n        emissions = self.classifier(sequence_output)\n\n        if labels is not None:\n            # Обратное распространение: CRF loss (отрицательный log-likelihood)\n            loss = -self.crf(\n                emissions,\n                labels,\n                mask=attention_mask.bool(),\n                reduction=\"mean\"\n            )\n            return loss\n        else:\n            # Инференс: decode лучших последовательностей меток\n            return self.crf.decode(\n                emissions,\n                mask=attention_mask.bool()\n            )\n\ndef calculate_f1(preds, labels, mask):\n    \"\"\"\n    Вычисление precision, recall и F1 по позициям пробелов.\n    Собираем все метки и предсказания по не-паддинговым токенам.\n    \"\"\"\n    pred_flat, true_flat = [], []\n    for pred_seq, true_seq, m in zip(preds, labels, mask):\n        for p, t, mm in zip(pred_seq, true_seq.tolist(), m.tolist()):\n            if mm == 1:  # учитываем только реальные токены\n                pred_flat.append(p)\n                true_flat.append(t)\n    p, r, f1, _ = precision_recall_fscore_support(\n        true_flat, pred_flat,\n        average=\"binary\",\n        pos_label=1\n    )\n    return p, r, f1\n\ndef train_epoch(model, dataloader, optimizer, device):\n    \"\"\"\n    Одна эпоха обучения:\n      - model.train() для включения dropout.\n      - Проход в tqdm для визуального контроля прогресса.\n      - Накопление и вывод среднего loss.\n    \"\"\"\n    model.train()\n    total_loss = 0.0\n    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n    for batch in progress_bar:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        # Прямой проход и вычисление loss\n        loss = model(input_ids, attention_mask, labels)\n        optimizer.zero_grad()\n        loss.backward()       \n        optimizer.step()      \n\n        total_loss += loss.item()\n        avg_loss = total_loss / (progress_bar.n + 1)\n        progress_bar.set_postfix(loss=f\"{avg_loss:.4f}\")\n\n    return total_loss / len(dataloader)\n\ndef evaluate(model, dataloader, device):\n    \"\"\"\n    Оценка на валидации:\n      - model.eval() для отключения dropout.\n      - Сбор предсказаний без градиентов.\n      - Возврат precision, recall и F1.\n    \"\"\"\n    model.eval()\n    all_preds, all_labels, all_mask = [], [], []\n    progress_bar = tqdm(dataloader, desc=\"Validation\", leave=False)\n    with torch.no_grad():\n        for batch in progress_bar:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            preds = model(input_ids, attention_mask)\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu())\n            all_mask.extend(attention_mask.cpu())\n            progress_bar.update(0)\n\n    return calculate_f1(all_preds, all_labels, all_mask)\n\n\n    \nfrom sklearn.model_selection import train_test_split\n\n# Гиперпараметры\nMODEL_NAME = \"ai-forever/ruRoberta-large\"\nBATCH_SIZE = 16\nLR = 2e-5\nEPOCHS = 3\nMAX_LEN = 128\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Предполагается, что data — это список (text_no_space, positions)\ntrain_ex, val_ex = train_test_split(data[:20000], test_size=0.2, random_state=42)\n# почему data[:20000] - обучение на полном датасете занимало слишком много времени (45 мин на эпоху)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:47.444161Z","iopub.execute_input":"2025-09-22T18:54:47.444750Z","iopub.status.idle":"2025-09-22T18:54:47.461961Z","shell.execute_reply.started":"2025-09-22T18:54:47.444726Z","shell.execute_reply":"2025-09-22T18:54:47.461099Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"\n# Даталоадеры\ntrain_ds = SpaceRestorationDataset(train_ex, tokenizer_name=MODEL_NAME, max_length=MAX_LEN)\nval_ds = SpaceRestorationDataset(val_ex, tokenizer_name=MODEL_NAME, max_length=MAX_LEN)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:49.603172Z","iopub.execute_input":"2025-09-22T18:54:49.603431Z","iopub.status.idle":"2025-09-22T18:54:52.566972Z","shell.execute_reply.started":"2025-09-22T18:54:49.603411Z","shell.execute_reply":"2025-09-22T18:54:52.566396Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = RuBERTCRFSpaceRestoration(MODEL_NAME).to(device)\noptimizer = AdamW(model.parameters(), lr=LR)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:52.568101Z","iopub.execute_input":"2025-09-22T18:54:52.568282Z","iopub.status.idle":"2025-09-22T18:54:53.922623Z","shell.execute_reply.started":"2025-09-22T18:54:52.568268Z","shell.execute_reply":"2025-09-22T18:54:53.922042Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:53.923758Z","iopub.execute_input":"2025-09-22T18:54:53.923966Z","iopub.status.idle":"2025-09-22T18:54:53.928548Z","shell.execute_reply.started":"2025-09-22T18:54:53.923949Z","shell.execute_reply":"2025-09-22T18:54:53.928033Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_f1 = 0.0\nfor epoch in range(EPOCHS):\n    train_loss = train_epoch(model, train_loader, optimizer, device)\n    p, r, f1 = evaluate(model, val_loader, device)\n    print(f\"Epoch {epoch+1}/{EPOCHS} — Train Loss: {train_loss:.4f} | Val F1: {f1:.4f} (P={p:.4f},R={r:.4f})\")\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), \"best_space_restoration.pth\")\n        print(f\"Saved best model with F1={best_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:54:57.571087Z","iopub.execute_input":"2025-09-22T18:54:57.571761Z","iopub.status.idle":"2025-09-22T19:38:54.012242Z","shell.execute_reply.started":"2025-09-22T18:54:57.571734Z","shell.execute_reply":"2025-09-22T19:38:54.011478Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/3 — Train Loss: 2.8866 | Val F1: 0.9602 (P=0.9475,R=0.9732)\nSaved best model with F1=0.9602\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/3 — Train Loss: 2.0639 | Val F1: 0.9612 (P=0.9420,R=0.9812)\nSaved best model with F1=0.9612\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/3 — Train Loss: 2.5323 | Val F1: 0.0000 (P=0.0000,R=0.0000)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"evaluate(model, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T19:40:39.366562Z","iopub.execute_input":"2025-09-22T19:40:39.367310Z","iopub.status.idle":"2025-09-22T19:41:35.668246Z","shell.execute_reply.started":"2025-09-22T19:40:39.367281Z","shell.execute_reply":"2025-09-22T19:41:35.667514Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"(0.0, 0.0, 0.0)"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"# Проверка на количество меток, почему то не получилось обучить модель \ndef check_label_distribution(dataloader):\n    label_counts = {0: 0, 1: 0}\n    for batch in dataloader:\n        labels = batch['labels']\n        mask = batch['attention_mask']\n        for label_seq, mask_seq in zip(labels, mask):\n            for l, m in zip(label_seq, mask_seq):\n                if m == 1:  # только не-паддинг токены\n                    label_counts[l.item()] += 1\n    print(\"Label distribution:\", label_counts)\n    return label_counts\n\ncheck_label_distribution(train_loader)\ncheck_label_distribution(val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:10:07.257790Z","iopub.execute_input":"2025-09-22T20:10:07.258103Z","iopub.status.idle":"2025-09-22T20:10:28.284511Z","shell.execute_reply.started":"2025-09-22T20:10:07.258080Z","shell.execute_reply":"2025-09-22T20:10:28.283923Z"}},"outputs":[{"name":"stdout","text":"Label distribution: {0: 231448, 1: 140108}\nLabel distribution: {0: 57304, 1: 34983}\n","output_type":"stream"},{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"{0: 57304, 1: 34983}"},"metadata":{}}],"execution_count":126},{"cell_type":"code","source":"data = {}\nwith open('/kaggle/input/avito-requests/dataset_1937770_3.txt', 'r') as f:\n    f = f.readlines()\n    \n    columns = f[0].strip().split(',')\n    for i in columns:\n        data[i] = []\n\n    for line in f[1:]:\n        # print(line)\n        res = line.strip().split(',', 1)\n        data[columns[0]].append(res[0])\n        data[columns[1]].append(res[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T19:54:32.242725Z","iopub.execute_input":"2025-09-22T19:54:32.243031Z","iopub.status.idle":"2025-09-22T19:54:32.267811Z","shell.execute_reply.started":"2025-09-22T19:54:32.243001Z","shell.execute_reply":"2025-09-22T19:54:32.267332Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame(data)\ndf['predicted_positions'] = df['id'].map(lambda x: [])\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T19:54:32.402306Z","iopub.execute_input":"2025-09-22T19:54:32.402513Z","iopub.status.idle":"2025-09-22T19:54:32.412618Z","shell.execute_reply.started":"2025-09-22T19:54:32.402497Z","shell.execute_reply":"2025-09-22T19:54:32.412056Z"}},"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"  id                 text_no_spaces predicted_positions\n0  0                куплюайфон14про                  []\n1  1             ищудомвПодмосковье                  []\n2  2  сдаюквартирусмебельюитехникой                  []\n3  3     новыйдивандоставканедорого                  []\n4  4                отдамдаромкошку                  []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text_no_spaces</th>\n      <th>predicted_positions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>куплюайфон14про</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ищудомвПодмосковье</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>сдаюквартирусмебельюитехникой</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>новыйдивандоставканедорого</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>отдамдаромкошку</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":121},{"cell_type":"code","source":"# 1. Загрузка модели и токенизатора\nMODEL_NAME = \"ai-forever/ruRoberta-large\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntokenizer = AutoTokenizer.from_pretrained(\n    MODEL_NAME, use_fast=True, add_prefix_space=True\n)\nmodel = RuBERTCRFSpaceRestoration(MODEL_NAME)\nmodel.load_state_dict(torch.load(\"best_space_restoration.pth\", map_location=DEVICE))\nmodel.to(DEVICE)\nmodel.eval()\n\n# 2. Функция для предсказания позиций пробелов\ndef predict_positions(text_ns: str) -> list[int]:\n    # Токенизация\n    enc = tokenizer(\n        text_ns,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128,\n        return_tensors=\"pt\"\n    )\n    input_ids = enc[\"input_ids\"].to(DEVICE)\n    attention_mask = enc[\"attention_mask\"].to(DEVICE)\n    offsets = enc[\"offset_mapping\"][0].tolist()\n\n    # Предсказание\n    with torch.no_grad():\n        preds = model(input_ids, attention_mask)[0]  # берем первый (и единственный) пример\n\n    # Собираем позиции по символам\n    positions = []\n    for token_idx, label in enumerate(preds):\n        if label == 1:\n            start, end = offsets[token_idx]\n            # добавляем позицию старта токена\n            positions.append(start)\n\n    # Фильтруем и сортируем\n    positions = sorted(set(p for p in positions if p < len(text_ns)))\n    return positions\n\n\n# Заполняем predicted_positions\ndf[\"predicted_positions\"] = df[\"text_no_spaces\"].apply(predict_positions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T19:54:35.079945Z","iopub.execute_input":"2025-09-22T19:54:35.080535Z","iopub.status.idle":"2025-09-22T19:55:10.962852Z","shell.execute_reply.started":"2025-09-22T19:54:35.080510Z","shell.execute_reply":"2025-09-22T19:55:10.962281Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ruRoberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T19:55:10.970369Z","iopub.execute_input":"2025-09-22T19:55:10.970629Z","iopub.status.idle":"2025-09-22T19:55:10.991172Z","shell.execute_reply.started":"2025-09-22T19:55:10.970605Z","shell.execute_reply":"2025-09-22T19:55:10.990513Z"}},"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"        id                  text_no_spaces   predicted_positions\n0        0                 куплюайфон14про           [5, 10, 12]\n1        1              ищудомвПодмосковье          [0, 2, 6, 7]\n2        2   сдаюквартирусмебельюитехникой           [3, 12, 20]\n3        3      новыйдивандоставканедорого        [5, 8, 16, 19]\n4        4                 отдамдаромкошку               [5, 10]\n...    ...                             ...                   ...\n1000  1000                        Янеусну.                [1, 3]\n1001  1001            Весна-яуженегреюпио.  [5, 6, 7, 9, 11, 16]\n1002  1002       Весна-скоровырастеттрава.        [5, 6, 13, 17]\n1003  1003  Весна-выпосмотрите,каккрасиво.     [5, 6, 8, 19, 22]\n1004  1004             Весна-гдемояголова?         [5, 6, 7, 12]\n\n[1005 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text_no_spaces</th>\n      <th>predicted_positions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>куплюайфон14про</td>\n      <td>[5, 10, 12]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ищудомвПодмосковье</td>\n      <td>[0, 2, 6, 7]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>сдаюквартирусмебельюитехникой</td>\n      <td>[3, 12, 20]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>новыйдивандоставканедорого</td>\n      <td>[5, 8, 16, 19]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>отдамдаромкошку</td>\n      <td>[5, 10]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>1000</td>\n      <td>Янеусну.</td>\n      <td>[1, 3]</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>1001</td>\n      <td>Весна-яуженегреюпио.</td>\n      <td>[5, 6, 7, 9, 11, 16]</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>1002</td>\n      <td>Весна-скоровырастеттрава.</td>\n      <td>[5, 6, 13, 17]</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>1003</td>\n      <td>Весна-выпосмотрите,каккрасиво.</td>\n      <td>[5, 6, 8, 19, 22]</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>1004</td>\n      <td>Весна-гдемояголова?</td>\n      <td>[5, 6, 7, 12]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1005 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":124},{"cell_type":"code","source":"# Оставляем только нужные столбцы\noutput_df = df[[\"id\", \"predicted_positions\"]]\n\n# скачать файл csv \noutput_df.to_csv(\"predicted_positions.csv\", index=False, encoding=\"utf-8\", header=[\"id\", \"predicted_positions\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:12:16.227642Z","iopub.execute_input":"2025-09-22T20:12:16.228368Z","iopub.status.idle":"2025-09-22T20:12:16.236166Z","shell.execute_reply.started":"2025-09-22T20:12:16.228342Z","shell.execute_reply":"2025-09-22T20:12:16.235479Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}